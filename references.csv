"Item type","Authors","Title","Journal","Publication year","Volume","Issue","Pages","Publisher","Date published","ISSN","URLs","DOI","Arxiv ID","Abstract","Keywords","Notes","Archive prefix","Eprint ID"
"Journal Article","Gour A,Gangodkar D,Tripathi V","A Review of Computer Vision Techniques for the Analysis of Vehicles","AIP Conference Proceedings","2022","2481","","","ieeexplore.ieee.org","2022","1551-7616","https://ieeexplore.ieee.org/abstract/document/5734852/;http://dx.doi.org/10.1063/5.0119992","10.1063/5.0119992","","Due to the increasing number of vehicles on the roads, a traffic analysis system is of peak importance. Various computer vision techniques and video analytics are used in the traffic analysis system to get useful information. This acquired information can be later used to make crucial judgements in real-time environment. This paper presents a comprehensive literature review in traffic analysis especially in the domains like moving vehicle detection, object identification and traffic volume estimation. The tabulated data presents the different algorithms along with their achieved performances. The paper also provides the limitations and the future scope of the discussed approaches.","Intelligent traffic system,moving vehicle detection,object identification,traffic volume estimation","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Beymer D,McLauchlan P,Coifman B,Malik J","Real-time computer vision system for measuring traffic parameters","Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition","1997","","","495-501","ieeexplore.ieee.org","1997","1063-6919","https://ieeexplore.ieee.org/abstract/document/609371/;http://dx.doi.org/10.1109/cvpr.1997.609371","10.1109/cvpr.1997.609371","","For the problem of tracking vehicles on freeways using machine vision, existing systems work well in free-flowing traffic. Traffic engineers, however, are more interested in monitoring freeways when there is congestion, and current systems break down for congested traffic due to the problem of partial occlusion. We are developing a feature-based tracking approach for the task of tracking vehicles under congestion. Instead of tracking entire vehicles, vehicle sub-features are tracked to make the system robust to partial occlusion. In order to group together sub-features that come from the same vehicle, the constraint of common motion is used. In this paper we describe the system, a real-time implementation using a network of DSP chips, and experiments of the system on approximately 44 lane hours of video data.","Automotive engineering,Computer vision,Detectors,Land vehicles,Layout,Machine vision,Real time systems,Road vehicles,Telecommunication traffic,Traffic control","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Coifman B,Beymer D,McLauchlan P,Malik J","A real-time computer vision system for vehicle tracking and traffic surveillance","Transportation Research Part C: Emerging Technologies","1998","6","4","271-288","Elsevier","1998","0968-090X","https://www.sciencedirect.com/science/article/pii/S0968090X98000199;http://dx.doi.org/10.1016/S0968-090X(98)00019-9","10.1016/S0968-090X(98)00019-9","","Increasing congestion on freeways and problems associated with existing detectors have spawned an interest in new vehicle detection technologies such as video image processing. Existing commercial image processing systems work well in free-flowing traffic, but the systems have difficulties with congestion, shadows and lighting transitions. These problems stem from vehicles partially occluding one another and the fact that vehicles appear differently under various lighting conditions. We are developing a feature-based tracking system for detecting vehicles under these challenging conditions. Instead of tracking entire vehicles, vehicle features are tracked to make the system robust to partial occlusion. The system is fully functional under changing lighting conditions because the most salient features at the given moment are tracked. After the features exit the tracking region, they are grouped into discrete vehicles using a common motion constraint. The groups represent individual vehicle trajectories which can be used to measure traditional traffic parameters as well as new metrics suitable for improved automated surveillance. This paper describes the issues associated with feature based tracking, presents the real-time implementation of a prototype system, and the performance of the system on a large data set.","Machine vision,Traffic surveillance,Vehicle tracking,Video image processing,Wide-area detection","Query date: 2023-03-13 22:02:47","",""
"Journal Article","H JD","Computer Vision Based Traffic Sign Sensing for Smart Transport","Journal of Innovative Image Processing","2019","1","01","11-19","irojournals.com","2019","","https://www.irojournals.com/iroiip/V1/I1/02.pdf;http://dx.doi.org/10.36548/jiip.2019.1.002","10.36548/jiip.2019.1.002","","The paper puts forward a real time traffic sign sensing (detection and recognition) frame work for enhancing the vehicles capability in order to have a save driving, path planning. The proposed method utilizes the capsules neural network that outperforms the convolutional neural network by eluding the necessities for the manual effort. The capsules network provides a better resistance for the spatial variance and the high reliability in the sensing of the traffic sign compared to the convolutional network. The evaluation of the capsule network with the Indian traffic data set shows a 15% higher accuracy when compared with the CNN and the RNN.","CNN,Capsule Neural Network,Intelligent Vehicle,Recurrent Neural Network,Traffic Sign Detection and Recognition (TS-DR)","Query date: 2023-03-13 22:02:47","",""
"Journal Article","González Á,Garrido MÁ,Llorca DF,Gavilan M,Fernandez JP,Alcantarilla PF,Parra I,Herranz F,Bergasa LM,Sotelo MÁ,Revenga De Toro P","Automatic traffic signs and panels inspection system using computer vision","IEEE Transactions on Intelligent Transportation Systems","2011","12","2","485-499","ieeexplore.ieee.org","2011","1524-9050","https://ieeexplore.ieee.org/abstract/document/5682406/;http://dx.doi.org/10.1109/TITS.2010.2098029","10.1109/TITS.2010.2098029","","Computer vision techniques applied to systems used on road maintenance, which are related either to traffic signs or to the road itself, are playing a major role in many countries because of the higher investment on public works of this kind. These systems are able to collect a wide range of information automatically and quickly, with the aim of improving road safety. In this context, the correct visibility of traffic signs and panels is vital for the safety of drivers. This paper describes an approach to the VISUAL Inspection of Signs and panEls (VISUALISE), which is an automatic inspection system, mounted onboard a vehicle, which performs inspection tasks at conventional driving speeds. VISUALISE allows for an improvement in the awareness of the road signaling state, supporting planning and decision making on the administration's and infrastructure operators' side. A description of the main computer vision techniques and some experimental results obtained from thousands of kilometers are presented. Finally, the conclusions of the system are described. \textcopyright 2006 IEEE.","Computer vision,dynamic inspection,retroreflection,traffic signs detection,traffic signs recognition","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Zinchenko V,Kondratenko G,Sidenko I,Kondratenko Y","Computer vision in control and optimization of road traffic","Proceedings of the 2020 IEEE 3rd International Conference on Data Stream Mining and Processing, DSMP 2020","2020","","","249-254","ieeexplore.ieee.org","2020","","https://ieeexplore.ieee.org/abstract/document/9204329/;http://dx.doi.org/10.1109/DSMP47368.2020.9204329","10.1109/DSMP47368.2020.9204329","","This paper presents the approaches and methods used in computer vision for the detection of moving objects and their tracking. Ways of using computer vision methods to optimize and control traffic are investigated. Every day, the number of vehicles on the roads is increasing and congestion problems are getting worse. The main goal in the development of modern traffic management systems is to create effective traffic management mechanisms in accordance with dynamic traffic conditions. Nowadays, the systems that regulate traffic have many drawbacks. The main ones, that such systems are working according to a predefined program and not being aware of the proper real-time data. This paper focuses on a novel approach to road traffic management by incorporating an intelligent traffic light controlling system using an algorithm that consumes real data from closed-circuit television (CCTV) cameras. As part of the solution, have been developed a program using a popular programming platform that would calculate sets of drive orders for traffic signal lights. The main goal of the proposed system is to provide better results in terms of reduced waiting delay for pedestrians and vehicles, shorter travel time, and increased average velocity of vehicles.","Artificial neural network,Computer vision,Decision-making,Traffic control","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Šegvić S,Brkić K,Kalafatić Z,Stanisavljević V,Ševrović M,Budimir D,Dadić I","A computer vision assisted geoinformation inventory for traffic infrastructure","IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC","2010","","","66-73","ieeexplore.ieee.org","2010","","https://ieeexplore.ieee.org/abstract/document/5624979/;http://dx.doi.org/10.1109/ITSC.2010.5624979","10.1109/ITSC.2010.5624979","","Geoinformation inventories are often employed as a tool for providing a comprehensive view onto the required state of traffic control infrastructure. They are especially important in road safety inspection where, in combination with georeferenced video, they enable repeatable off-line and off-site assessments as an attractive aternative to classic on-site inspection. Nevertheless, manual assessments are tedious and time-consuming even when performed off-line, and this seriously impairs the potential of the geoinformation inventory concept. This paper therefore researches a hypothesis that suitable georeferenced video processing techniques would allow reliable automation of the following operations: i) creation of the traffic inventory from the given video, and ii) assessing the video against the state in the inventory. Prominent computer vision approaches have been rigorously and systematically evaluated and the obtained results are presented. The results seem to support the hypothesis, although further work is required for a more definite answer. \textcopyright2010 IEEE.","Cameras,Computer vision,Global Positioning System,Image color analysis,Inspection,Roads,Training","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Kun AJ,Vámossy Z","Traffic monitoring with computer vision","SAMI 2009 - 7th International Symposium on Applied Machine Intelligence and Informatics, Proceedings","2009","","","131-134","ieeexplore.ieee.org","2009","","https://ieeexplore.ieee.org/abstract/document/4956624/;http://dx.doi.org/10.1109/SAMI.2009.4956624","10.1109/SAMI.2009.4956624","","Nowadays roads and streets are getting overcrowded, especially in bigger cities. Hence the main goal of our project is to build a traffic monitoring system which is able to detect the movement of cars and to track and count the different vehicles by analyzing a camera picture with the help of computer vision. The real-time process (15- 30 fps) of the video stream works at daylight. The traffic monitoring includes the followings: it accepts the video from a file or a camera, marks the moving vehicles with rectangles, and counts them. The system consists of three subsystems, these are the: Video Subsystem, Motion Detector Subsystem, Display/Control Subsystem. To maximize the speed of the program, each subsystem runs on different threads. To accept the visual information DirectShow is used, and the image processing is partially done with the DirectCV wrapper [6] for OpenCV. For motion detection, the system uses a Gaussian Mixture Model with background segmentation. There is an opportunity to mask the monitoring area also. With the mask it is possible to filter out for example the sidewalks and the opposite traffic direction so that our system avoids these parts of the image. The mask area can be easily built by placing a sequence of points which are the vertexes of a polygon. To create a polygon from the sequence of points a hybrid algorithm is applied which combines the 2opt heuristic method and a genetic algorithm. Connected component labeling algorithm is used for object detection, which utilizes a decision tree and Union-Find data structure in order to achieve the best performance. Recently we are testing a shadow removal algorithm based on edge detection in order to detect the objects in traffic scenes more accurately. \textcopyright 2009 IEEE.","Cameras,Cities and towns,Computer vision,Computerized monitoring,Image edge detection,Motion detection,Object detection,Roads,Tracking,Vehicle detection","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Kumaran SK,Mohapatra S,Dogra DP,Roy PP,Kim BG","Computer vision-guided intelligent traffic signaling for isolated intersections","Expert Systems with Applications","2019","134","","267-278","Elsevier","2019","0957-4174","https://www.sciencedirect.com/science/article/pii/S0957417419303847;http://dx.doi.org/10.1016/j.eswa.2019.05.049","10.1016/j.eswa.2019.05.049","","Computer vision-guided traffic management is an emerging area of research. Intelligent traffic signal control using computer vision is a less explored area of research. In this paper, we propose a new approach of traffic flow-based intelligent signal timing by temporally clustering optical flow features of moving vehicles using Temporal Unknown Incremental Clustering (TUIC) model. First, we propose a new inference scheme that works approximately 5-times faster as compared to the one originally proposed in TUIC in a dense traffic intersection. The new inference scheme can trace clusters representing moving objects that may be occluded while being tracked. Cluster counts of approach roads have been used for signal timing for traffic intersections. It is done by detecting cluster motion inside the regions-of-interest (ROI) marked at the entry and exit locations of intersection approaches. Departure rates are learned using Gaussian regression to parameterize traffic variations. Using the learned parameters as a function of cluster count, an adaptive signal timing algorithm, namely Throughput and Average Waiting Time Optimization (TAWTO) has been proposed. Experimental results reveal that the proposed method can achieve better average waiting time and throughput as compared to the state-of-the-art signal timing algorithms. We intend to publish two datasets as part of this work for enabling the research community to explore computer vision aided solutions for typical problems such as intelligent traffic controlling, violation detection in chaotic road intersections, etc.","Dirichlet process mixture model,Isolated intersections,Traffic signal timing,Unsupervised machine learning,Visual surveillance","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Bartilson DT,Wieghaus KT,Hurlebaus S","Target-less computer vision for traffic signal structure vibration studies","Mechanical Systems and Signal Processing","2015","60","","571-582","Elsevier","2015","1096-1216","https://www.sciencedirect.com/science/article/pii/S0888327015000072;http://dx.doi.org/10.1016/j.ymssp.2015.01.005","10.1016/j.ymssp.2015.01.005","","The presented computer vision method allows for non-contact, target-less determination of traffic signal structure displacement and modal parameters, including mode shapes. By using an analytical model to relate structural displacement to stress, it is shown possible to utilize a rapid set-up and take-down computer vision-based system to infer structural stresses to a high degree of precision. Using this computer vision method, natural frequencies of the structure are determined with accuracy similar to strain gage and string potentiometer instrumentation. Even with structural displacements measured at less than 0.5 pixel, excellent mode shape results are obtained. Finally, one-minute equivalent stress ranges from ambient wind excitation are found to have excellent agreement between the inferred stress from strain gage data and stresses calculated from computer vision tied to an analytical stress model. This demonstrates the ability of this method and implemented system to develop fatigue life estimates using wind velocity data and modest technical means.","Computer vision,Modal testing,Structure dynamics,Target-less,Vibration","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Ijjina EP,Chand D,Gupta S,Goutham K","Computer Vision-based Accident Detection in Traffic Surveillance","2019 10th International Conference on Computing, Communication and Networking Technologies, ICCCNT 2019","2019","","","","ieeexplore.ieee.org","2019","","https://ieeexplore.ieee.org/abstract/document/8944469/;http://dx.doi.org/10.1109/ICCCNT45670.2019.8944469;http://arxiv.org/abs/1911.10037","10.1109/ICCCNT45670.2019.8944469","1911.10037","Computer vision-based accident detection through video surveillance has become a beneficial but daunting task. In this paper, a neoteric framework for detection of road accidents is proposed. The proposed framework capitalizes on Mask R-CNN for accurate object detection followed by an efficient centroid based object tracking algorithm for surveillance footage. The probability of an accident is determined based on speed and trajectory anomalies in a vehicle after an overlap with other vehicles. The proposed framework provides a robust method to achieve a high Detection Rate and a low False Alarm Rate on general road-traffic CCTV surveillance footage. This framework was evaluated on diverse conditions such as broad daylight, low visibility, rain, hail, and snow using the proposed dataset. This framework was found effective and paves the way to the development of general-purpose vehicular accident detection algorithms in real-time.","Accident Detection,Centroid based Object Tracking,Mask R-CNN,Vehicular Collision","Query date: 2023-03-13 22:02:47","arXiv","1911.10037"
"Journal Article","Mhalla A,Chateau T,Gazzah S,Amara NE","An Embedded Computer-Vision System for Multi-Object Detection in Traffic Surveillance","IEEE Transactions on Intelligent Transportation Systems","2019","20","11","4006-4018","ieeexplore.ieee.org","2019","1558-0016","https://ieeexplore.ieee.org/abstract/document/8546791/;http://dx.doi.org/10.1109/TITS.2018.2876614","10.1109/TITS.2018.2876614","","Intelligent traffic systems for traffic surveillance and monitoring have become a topic of great interest to some cities in the world. Generally, the existing traffic surveillance systems are made up of costly equipment with complicated operational procedures and have difficulties with congestion, occlusion, and lighting night/day and day/night transitions. In this paper, we propose an embedded system for traffic surveillance that can be utilized under these challenging conditions. This system analyses traffic and particularly focuses on the problem of detecting and categorizing traffic objects in several traffic scenarios. Moreover, it contains a robust detector produced by an original specialization framework. The proposed specialization framework utilizes a generic deep detector so as to improve the detection accuracy in a specific traffic scenario. The experiments demonstrate that the proposed specialization framework presents encouraging results for multi-traffic object detection and outperforms the state-of-the-art specialization frameworks on several public traffic datasets.","MF R-CNN,Traffic surveillance,deep learning,embedded system,likelihood function,traffic object detection,transfer learning","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Liu G,Shi H,Kiani A,Khreishah A,Lee J,Ansari N,Liu C,Yousef MM","Smart Traffic Monitoring System Using Computer Vision and Edge Computing","IEEE Transactions on Intelligent Transportation Systems","2022","23","8","12027-12038","ieeexplore.ieee.org","2022","1558-0016","https://ieeexplore.ieee.org/abstract/document/9546662/;http://dx.doi.org/10.1109/TITS.2021.3109481;http://arxiv.org/abs/2109.03141","10.1109/TITS.2021.3109481","2109.03141","Traffic management systems capture tremendous video data and leverage advances in video processing to detect and monitor traffic incidents. The collected data are traditionally forwarded to the traffic management center (TMC) for in-depth analysis and may thus exacerbate the network paths to the TMC. To alleviate such bottlenecks, we propose to utilize edge computing by equipping edge nodes that are close to cameras with computing resources (e.g., cloudlets). A cloudlet, with limited computing resources as compared to TMC, provides limited video processing capabilities. In this paper, we focus on two common traffic monitoring tasks, congestion detection, and speed detection, and propose a two-tier edge computing based model that takes into account of both the limited computing capability in cloudlets and the unstable network condition to the TMC. Our solution utilizes two algorithms for each task, one implemented at the edge and the other one at the TMC, which are designed with the consideration of different computing resources. While the TMC provides strong computation power, the video quality it receives depends on the underlying network conditions. On the other hand, the edge processes very high-quality video but with limited computing resources. Our model captures this trade-off. We evaluate the performance of the proposed two-tier model as well as the traffic monitoring algorithms via test-bed experiments under different weather as well as network conditions and show that our proposed hybrid edge-cloud solution outperforms both the cloud-only and edge-only solutions.","Traffic monitoring,edge-computing,incidents detection,video analytic","Query date: 2023-03-13 22:02:47","arXiv","2109.03141"
"Journal Article","Geronimo D,Serrat J,Lopez AM,Baldrich R","Traffic sign recognition for computer vision project-based learning","IEEE Transactions on Education","2013","56","3","364-371","ieeexplore.ieee.org","2013","0018-9359","https://ieeexplore.ieee.org/abstract/document/6425440/;http://dx.doi.org/10.1109/TE.2013.2239997","10.1109/TE.2013.2239997","","This paper presents a graduate course project on computer vision. The aim of the project is to detect and recognize traffic signs in video sequences recorded by an on-board vehicle camera. This is a demanding problem, given that traffic sign recognition is one of the most challenging problems for driving assistance systems. Equally, it is motivating for the students given that it is a real-life problem. Furthermore, it gives them the opportunity to appreciate the difficulty of real-world vision problems and to assess the extent to which this problem can be solved by modern computer vision and pattern classification techniques taught in the classroom. The learning objectives of the course are introduced, as are the constraints imposed on its design, such as the diversity of students' background and the amount of time they and their instructors dedicate to the course. The paper also describes the course contents, schedule, and how the project-based learning approach is applied. The outcomes of the course are discussed, including both the students' marks and their personal feedback. \textcopyright 1963-2012 IEEE.","Computer vision (CV),Master's degree,project-based learning (PBL),traffic sign","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Krishna,Poddar M,Giridhar MK,Prabhu AS,Umadevi V","Automated traffic monitoring system using computer vision","Proceedings of 2016 International Conference on ICT in Business, Industry, and Government, ICTBIG 2016","2017","","","","ieeexplore.ieee.org","2017","","https://ieeexplore.ieee.org/abstract/document/7892717/;http://dx.doi.org/10.1109/ICTBIG.2016.7892717","10.1109/ICTBIG.2016.7892717","","We have rules to govern traffic to ensure a smooth movement of traffic. We need to make sure that traffic violations do not occur and also penalize the offenders. We are considering the aspect of over-speeding for our implementation and would like to do our bit to supervise such an action. We receive the traffic surveillance video input from a camera. We have implemented a system which measures the number of vehicles and also checks for speed limit violation. The system has an accuracy of 98.96% for vehicle count detection and an accuracy of 98.14% for speed violation detection. We use the concept of multiple reference lines for identifying vehicles. Using the total duration of frames the vehicle took to cross the reference lines we determine the speed and hence the possibility of a traffic violation. It also helps in providing an idea regarding the traffic in any area of interest.","multiple reference lines,pixel values variation,speed estimation,speed violation identification,traffic analysis,vehicle count","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Nodado JT,Morales HC,Abugan MA,Olisea JL,Aralar AC,Loresco PJ","Intelligent Traffic Light System Using Computer Vision with Android Monitoring and Control","IEEE Region 10 Annual International Conference, Proceedings/TENCON","2019","2018-October","","2461-2466","ieeexplore.ieee.org","2019","2159-3450","https://ieeexplore.ieee.org/abstract/document/8650084/;http://dx.doi.org/10.1109/TENCON.2018.8650084","10.1109/TENCON.2018.8650084","","One of the predominant cause of the diminishing productivity of the Philippines that affects its residents and industry sectors alike is no other than the unresolved traffic. Numerous efforts have been implemented in the country to regulate traffic including road expansion, highway development and application of several traffic schemes. One of the research thrust being studied is the solution to the limitation of traditional traffic light systems. Existing literatures in traffic light system embarked on intelligent transportation system (ITS) that is typically based its operation on real-time traffic density data, however implemented in limited control. This paper discussed an approach in developing traffic signaling system capable of prioritizing congested lanes based on real-time traffic density data and integrated with an automated and manual control ported in a mobile android-based application. The system worked with CCTV cameras positioned at every lane of the intersection for the acquisition of traffic images transmitted to the Raspberry Pi 3 microcontroller for traffic density calculation using image processing. It utilized a traffic monitoring system and traffic lights operation control via a mobile android-based application. The system was tested and yielded an average of 92.83% and 85.77% vehicle detection rate for daytime and nighttime respectively. Moreover, an overall system reliability of 92.82% and 85.77% were obtained during daytime and nighttime testing based on the android GUI, lane prioritization and traffic light response. Future work involved integrating the Internet of Things (IoT) on the traffic light system for a wider scope interconnected implementation.","Image Processing,Intelligent transportation system,Mobile Android-Based Application,Traffic light control,computer vision","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Huang MC,Yen SH","A real-time and color-based computer vision for traffic monitoring system","2004 IEEE International Conference on Multimedia and Expo (ICME)","2004","3","","2119-2122","ieeexplore.ieee.org","2004","","https://ieeexplore.ieee.org/abstract/document/1394685/;http://dx.doi.org/10.1109/icme.2004.1394685","10.1109/icme.2004.1394685","","This paper presents a vision-based traffic monitoring system via analyzing color image sequences of traffic scenes recorded by a stationary camera mounted on a tall building or pedestrian crossing bridge near a traffic light. The system algorithms consist of building initial background, segmenting foreground, shadow separation, vehicle location, vehicle tracking, and background updating. The YCrCb color space is adopted in our algorithm. It provides us an accurate and robust device for foreground and shadow detection. Our system can accurately locate and track vehicles from image sequences. It is fast enough to operate in real time, insensitive to lighting and weather conditions, and only requires a minimal amount of initialization. Experimental results from town scenes are provided which demonstrate the effectiveness of our system.","Background adaptation,Shadow detection,Traffic monitoring system,Traffic scene,Vehicle detection,Vehicle tracking","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Chowdhury MF,Ryad Ahmed Biplob M,Uddin J","Real time traffic density measurement using computer vision and dynamic traffic control","2018 Joint 7th International Conference on Informatics, Electronics and Vision and 2nd International Conference on Imaging, Vision and Pattern Recognition, ICIEV-IVPR 2018","2019","","","353-356","ieeexplore.ieee.org","2019","","https://ieeexplore.ieee.org/abstract/document/8641039/;http://dx.doi.org/10.1109/ICIEV.2018.8641039","10.1109/ICIEV.2018.8641039","","In recent times, traffic jam has become a common problem in the major cities all over the world. In this paper, we propose a dynamic traffic control system by measuring the traffic density at the intersections by real time video feeds and image processing. A video sample was collected and then Mixture of Gaussian algorithm was used for background subtraction method and for foreground detection to keep the count of the cars in each lane. The vehicles are detected by their line of centroid. A movement in centroid confirms a vehicle. The traffic lights at the intersections will change dynamically according to the conditions of traffic that will be detected from the video feeds. In between two intersections, there will be multiple cameras installed to count the number of vehicles entering and leaving each intersection. Furthermore, we restrict the vehicles to take right turns in the intersections. To validate our work, density measurement algorithm, images of live feeds and logics for traffic control are shown in this paper.","Background subtraction,Dynamic traffic control,Foreground detection,Mixture of Gaussian,Real-time video processing","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Basheer Ahmed MI,Zaghdoud R,Ahmed MS,Sendi R,Alsharif S,Alabdulkarim J,Albin Saad BA,Alsabt R,Rahman A,Krishnasamy G","A Real-Time Computer Vision Based Approach to Detection and Classification of Traffic Incidents","Big Data and Cognitive Computing","2023","7","1","","mdpi.com","2023","2504-2289","https://www.mdpi.com/2504-2289/7/1/22;http://dx.doi.org/10.3390/bdcc7010022","10.3390/bdcc7010022","","To constructively ameliorate and enhance traffic safety measures in Saudi Arabia, a prolific number of AI (Artificial Intelligence) traffic surveillance technologies have emerged, including Saher, throughout the past years. However, rapidly detecting a vehicle incident can play a cardinal role in ameliorating the response speed of incident management, which in turn minimizes road injuries that have been induced by the accident's occurrence. To attain a permeating effect in increasing the entailed demand for road traffic security and safety, this paper presents a real-time traffic incident detection and alert system that is based on a computer vision approach. The proposed framework consists of three models, each of which is integrated within a prototype interface to fully visualize the system's overall architecture. To begin, the vehicle detection and tracking model utilized the YOLOv5 object detector with the DeepSORT tracker to detect and track the vehicles' movements by allocating a unique identification number (ID) to each vehicle. This model attained a mean average precision (mAP) of 99.2%. Second, a traffic accident and severity classification model attained a mAP of 83.3% while utilizing the YOLOv5 algorithm to accurately detect and classify an accident's severity level, sending an immediate alert message to the nearest hospital if a severe accident has taken place. Finally, the ResNet152 algorithm was utilized to detect the ignition of a fire following the accident's occurrence; this model achieved an accuracy rate of 98.9%, with an automated alert being sent to the fire station if this perilous event occurred. This study employed an innovative parallel computing technique for reducing the overall complexity and inference time of the AI-based system to run the proposed system in a concurrent and parallel manner.","DeepSORT tracking,accident severity classification,computer vision,object detection,postcollision vehicle fire detection,vehicle detection","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Guo F,Wang Y,Qian Y","Computer vision-based approach for smart traffic condition assessment at the railroad grade crossing","Advanced Engineering Informatics","2022","51","","","Elsevier","2022","1474-0346","https://www.sciencedirect.com/science/article/pii/S1474034621002068;http://dx.doi.org/10.1016/j.aei.2021.101456","10.1016/j.aei.2021.101456","","Slow-moving or stopped trains at highway-railroad grade crossings, especially in the populated metropolitan areas, not only cause significant traffic delays to commuters, but also prevent first responders from timely responding to emergencies. In this study, the researchers introduce an automated video analysis, detection and tracking system to evaluate the traffic conditions, analyze blocked vehicle behaviors at grade crossings, and predict the decongestion time under a simplified scenario. A novel YOLOv3-SPP+ model has been developed to improve the detection performance with dividing the image from finer to coarser levels and enhance local features. The SORT module has been integrated to the model for a simple yet efficient manner to track vehicles at the railroad grade crossing. Two field datasets at the Columbia, SC, with train blockage video records have been tested. The model training performance has been evaluated by mAP @0.5, F1 score, and total loss. Based on the training results, our model outperforms other YOLO series models. The field tracking performance has been assessed by the ratio between prediction and ground truth. The mean value of accuracy of our test cases is 92.37%, indicating a reliable tracking performance. In addition, the present results indicate the traffic during and after the crossing blockage does follow a pattern, and there is a general trend of the behavior of the vehicles waiting or taking an alternative route. A good linear correlation between the decongestion time and the number of blocked vehicles has been observed at the monitored grade crossing at the City of Columbia, SC.","Computer vision,Deep learning,Grade crossing,Traffic assessment,Traffic delay","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Magrini M,Moroni D,Palazzese G,Pieri G,Leone G,Salvetti O","Computer Vision on Embedded Sensors for Traffic Flow Monitoring","IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC","2015","2015-October","","161-166","ieeexplore.ieee.org","2015","","https://ieeexplore.ieee.org/abstract/document/7313127/;http://dx.doi.org/10.1109/ITSC.2015.35","10.1109/ITSC.2015.35","","Capillary monitoring of traffic in urban environment is key to a more sustainable mobility in smart cities. In this context, the use of low cost technologies is mandatory to avoid scalability issues that would prevent the adoption of monitoring solutions at the full city scale. In this paper, we introduce a low power and low cost sensor equipped with embedded vision logics that can be used for building Smart Camera Networks (SCN) for applications in Intelligent Transportation System (ITS), in particular, we describe an ad hoc computer vision algorithm for estimation of traffic flow and discuss the findings obtained through an actual field test.","Embedded Systems,Intelligent Transport Systems (ITS),Real-Time Imaging","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Lira G,Kokkinogenis Z,Rossetti RJ,Moura DC,Rúbio T","A computer-vision approach to traffic analysis over intersections","IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC","2016","","","47-53","ieeexplore.ieee.org","2016","","https://ieeexplore.ieee.org/abstract/document/7795530/;http://dx.doi.org/10.1109/ITSC.2016.7795530","10.1109/ITSC.2016.7795530","","In recent years, there has been an interest in detailed monitoring of road traffic, particularly in intersections, in order to obtain a statistical model of the flow of vehicles through them. These models aid in the optimization of traffic management and allow for smarter transportation systems. While conventional methods sensors at each of the intersections entrances/exits allow for counting, are limited in the sense that it is impossible to track a vehicle from origin to destination. A solution is presented using computer vision algorithms to footage obtained from drones floating over an intersection, in order to identify and track vehicles so that a statistical model may be extracted. This model is based on said association of an origin and a destination. The algorithm employs background subtraction and vehicle tracking with Kalman filters. The most significant challenge was how to compensate for camera movement. Based on the implementation which was developed, this the approach proved useful for tracking cars, buses , and trucks under some conditions. This paper is based upon research work done for a masters dissertation project.","Cameras,Computer vision,Feature extraction,Roads,Sensors,Tracking,Vehicles","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Billones RK,Bandala AA,Gan Lim LA,Sybingco E,Fillone AM,Dadios EP","Microscopic road traffic scene analysis using computer vision and traffic flow modelling","Journal of Advanced Computational Intelligence and Intelligent Informatics","2018","22","5","704-710","jstage.jst.go.jp","2018","1883-8014","https://www.jstage.jst.go.jp/article/jaciii/22/5/22_704/_article/-char/ja/;http://dx.doi.org/10.20965/jaciii.2018.p0704","10.20965/jaciii.2018.p0704","","This paper presents the development of a vision-based system for microscopic road traffic scene analysis and understanding using computer vision and computational intelligence techniques. The traffic flow model is calibrated using the information obtained from the road-side cameras. It aims to demonstrate an understanding of different levels of traffic scene analysis from simple detection, tracking, and classification of traffic agents to a higher level of vehicular and pedestrian dynamics, traffic congestion build-up, and multiagent interactions. The study used a video dataset suitable for analysis of a T-intersection. Vehicle detection and tracking have 88.84% accuracy and 88.20% precision. The system can classify private cars, public utility vehicles, buses, and motorcycles. Vehicular flow of every detected vehicles from origin to destination are also monitored for traffic volume estimation, and volume distribution analysis. Lastly, a microscopic traffic model for a T-intersection was developed to simulate a traffic response based on actual road scenarios.","Computer vision,Intelligent transport systems,Microscopic traffic flow modelling,Traffic scene analysis,Vehicle detection and tracking","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Kanagaraj N,Hicks D,Goyal A,Tiwari S,Singh G","Deep learning using computer vision in self driving cars for lane and traffic sign detection","International Journal of System Assurance Engineering and Management","2021","12","6","1011-1025","Springer","2021","0976-4348","https://link.springer.com/article/10.1007/s13198-021-01127-6;http://dx.doi.org/10.1007/s13198-021-01127-6","10.1007/s13198-021-01127-6","","Recently, the amount of research in the field of self-driving cars has grown significantly with autonomous vehicles having clocked in more than 10 million miles, providing a substantial amount of data for use in training and testing. The most complex part of training is the use of computer vision for feature extraction and object detection in real-time. Much relevant research has been done on improving the algorithms in the area of image segmentation. The proposed idea presents the use of Convoluted Neural Networks using Spatial Transformer Networks and lane detection in real time to increase the efficiency of autonomous vehicles. The depth of the neural network will help in training vehicles and during the testing phase, the vehicles will learn to make decisions based on the training data. In case of sudden changes to the environment, the vehicle will be able to make decisions quickly to prevent damage or danger to lives. Along with lane detection, a self-driving car must also be able to detect traffic signs. The proposed approach uses the Adam Optimizer which runs on top of the LeNet-5 architecture. The LeNet-5 architecture is analyzed and compared with the Feed Forward Neural Network approach. The accuracy of the LeNet-5 architecture was found to be 97% while the accuracy of the Feed Forward Neural Network was 94%.","Autonomous vehicles,Computer vision,Deep learning,Self-driving cars","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Qi B,Zhao W,Zhang H,Jin Z,Wang X,Runge T","Automated traffic volume analytics at road intersections using computer vision techniques","ICTIS 2019 - 5th International Conference on Transportation Information and Safety","2019","","","161-169","ieeexplore.ieee.org","2019","","https://ieeexplore.ieee.org/abstract/document/8883683/;http://dx.doi.org/10.1109/ICTIS.2019.8883683","10.1109/ICTIS.2019.8883683","","As the hardware cost decreases, more and more cameras have been deployed and used to monitor traffics. Widely deployed cameras enable a wide range of computer vision-based applications for traffic analytics. In this work, we propose a computer vision-based intelligent system which can analysis traffic at road interactions. Our system leverages existing traffic monitoring cameras and applies computer vision techniques to provide detailed traffic analysis results. To achieve these goals, we develop a deep learning object detection model based on Single Shot MultiBox Detector (SSD). Our approach is able to detect and track vehicles, pedestrians, traffic signs and other related-objects on the road. We build a robust model to analysis the detected objects, our system could estimate traffic volume and further infer traffic congestion, traffic rule violation and so on. To evaluate the proposed model, we use video data collected from multiple cameras at several intersections in real-world environments. The evaluation results show that our system is able to provide reliable and accurate traffic analysis results in real time. In addition, we also tested our system under different light conditions, and results show that our system could achieve similar accuracies under different light conditions.","Audio processing,CNN,Driver distraction,Sensor fusion,Traffic context information","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Santhosh KK,Dogra DP,Roy PP","Anomaly Detection in Road Traffic Using Visual Surveillance: A Survey","ACM Computing Surveys","2021","53","6","","dl.acm.org","2021","1557-7341","https://dl.acm.org/doi/abs/10.1145/3417989;http://dx.doi.org/10.1145/3417989;http://arxiv.org/abs/1901.08292","10.1145/3417989","1901.08292","Computer vision has evolved in the last decade as a key technology for numerous applications replacing human supervision. Timely detection of traffic violations and abnormal behavior of pedestrians at public places through computer vision and visual surveillance can be highly effective for maintaining traffic order in cities. However, despite a handful of computer vision-based techniques proposed in recent times to understand the traffic violations or other types of on-road anomalies, no methodological survey is available that provides a detailed insight into the classification techniques, learning methods, datasets, and application contexts. Thus, this study aims to investigate the recent visual surveillance-related research on anomaly detection in public places, particularly on road. The study analyzes various vision-guided anomaly detection techniques using a generic framework such that the key technical components can be easily understood. Our survey includes definitions of related terminologies and concepts, judicious classifications of the vision-guided anomaly detection approaches, detailed analysis of anomaly detection methods including deep learning-based methods, descriptions of the relevant datasets with environmental conditions, and types of anomalies. The study also reveals vital gaps in the available datasets and anomaly detection capability in various contexts, and thus gives future directions to the computer vision-guided anomaly detection research. As anomaly detection is an important step in automatic road traffic surveillance, this survey can be a useful resource for interested researchers working on solving various issues of Intelligent Transportation Systems (ITS).","Learning methods,classification,road traffic analysis","Query date: 2023-03-13 22:02:47","arXiv","1901.08292"
"Journal Article","Alhuthali SA,Zia MY,Rashid M","A Simplified Traffic Flow Monitoring System Using Computer Vision Techniques","Proceedings of 2022 2nd International Conference on Computing and Information Technology, ICCIT 2022","2022","","","167-170","ieeexplore.ieee.org","2022","","https://ieeexplore.ieee.org/abstract/document/9711550/;http://dx.doi.org/10.1109/ICCIT52419.2022.9711550","10.1109/ICCIT52419.2022.9711550","","Millions of Muslims from all over the world visit the holy city of Makkah to perform Umrah throughout the year, but especially in the month of Ramadan the quantity of pilgrims increases significantly. Same conditions can be observed in the month of Dhu al-Hijjah during the Hajj season. To transfer the pilgrims from one place to another various many vehicles are used. It is very important to monitor the traffic flow during these days to avoid any congestion which may lead to any mishap. Therefore, there is a need for a traffic flow monitoring system that can be used to count vehicles, and classify them according to their size to facilitate traffic management. A computer vision based system is proposed in this research that uses MATLAB vision tool to identify and count the vehicles. The novelty of the system is its simplicity that uses a camera as a video source, then suitable algorithms are implemented on it for processing. A portion of a video is used for system training that first obtains a binary foreground from the initial frame, then removes noise and then counts the vehicles present in the frame. The functionality of the proposed system has been verified by a number of experiments with the accuracy of 90%. It can be easily implemented in various environments for vehicles counting that can be used for better traffic management.","Computer Vision,Image Processing,MATLAB,Traffic Monitoring,Vehicle Classification,Vehicle Detection","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Ci W,Xu T,Lin R,Lu S","A Novel Method for Unexpected Obstacle Detection in the Traffic Environment Based on Computer Vision","Applied Sciences (Switzerland)","2022","12","18","","mdpi.com","2022","2076-3417","https://www.mdpi.com/1816006;http://dx.doi.org/10.3390/app12188937","10.3390/app12188937","","Obstacle detection is the basis for the Advanced Driving Assistance System (ADAS) to take obstacle avoidance measures. However, it is a very essential and challenging task to detect unexpected obstacles on the road. To this end, an unexpected obstacle detection method based on computer vision is proposed. We first present two independent methods for the detection of unexpected obstacles: a semantic segmentation method that can highlight the contextual information of unexpected obstacles on the road and an open-set recognition algorithm that can distinguish known and unknown classes according to the uncertainty degree. Then, the detection results of the two methods are input into the Bayesian framework in the form of probabilities for the final decision. Since there is a big difference between semantic and uncertainty information, the fusion results reflect the respective advantages of the two methods. The proposed method is tested on the Lost and Found dataset and evaluated by comparing it with the various obstacle detection methods and fusion strategies. The results show that our method improves the detection rate while maintaining a relatively low false-positive rate. Especially when detecting unexpected long-distance obstacles, the fusion method outperforms the independent methods and keeps a high detection rate.","Bayesian fusion,computer vision,open-set recognition algorithm,semantic segmentation,uncertainty degree,unexpected obstacle detection","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Yang Hfrank,Ling Y,Kopca C,Ricord S,Wang Y","Cooperative traffic signal assistance system for non-motorized users and disabilities empowered by computer vision and edge artificial intelligence","Transportation Research Part C: Emerging Technologies","2022","145","","","Elsevier","2022","0968-090X","https://www.sciencedirect.com/science/article/pii/S0968090X22003096;http://dx.doi.org/10.1016/j.trc.2022.103896","10.1016/j.trc.2022.103896","","Information and communication technology has many promising benefits including improvement the traffic network capacity, efficiency, and stability. However, to date, most of the improvements in signal management and interactions in connected vehicle environments focus solely on the vehicular side. This has led to a massive gap for non-motorized users and vulnerable road users. Specifically, deficit perception capability, inconsistent dissemination, obsolescent acquisition techniques, and ignorance of equality make the current experience of the active non-motorized users inconvenient and risky, especially for those with disabilities. To serve the users in an unbiased and automated way, a novel cooperated signal phase and timing (SPaT) services infrastructure — Vision Enhanced Non-motorized Users Services (VENUS) smart node is proposed. With customized up-to-date computer vision algorithms and artificial intelligence pipelines on the edge, VENUS smart node can collect necessary active-user information (including location, class, pose direction and mobility status), and generate directional crossing request for every pedestrian and cyclist in real time. Meanwhile, the improved communication system makes the VENUS node a reliable information hub to share the SPaT messages and carry interactions to/from the signal controller, connected vehicles and user personal information devices (i.e., cell phones, wearable devices) through various protocols. Based on extensive experimentation, 1076 testing users from six intersections, the VENUS sensing achieves 90.24% accuracy on directional-aware crossing trigger generation and 89.87% accuracy on mobility status estimation for normal users and four types of disabled persons. Furthermore, the VENUS smart node is fully compatible with the connected vehicles environment, and improves the signal system at low cost, mainly due to its flexibility and adaptability with existing infrastructure. The VENUS smart node is the first connected infrastructure architecture that integrates traffic sensing, data processing and information dissemination together for the self-operating indistinguishable signal services based on edge computing.","Computer vision,Connected vehicle,Disability user,Edge computing,Signal Phase and Timing (SPaT),Smart infrastructure","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Sun X,Ding J,Dalla Chiara G,Cheah L,Cheung NM","A generic framework for monitoring local freight traffic movements using computer vision-based techniques","5th IEEE International Conference on Models and Technologies for Intelligent Transportation Systems, MT-ITS 2017 - Proceedings","2017","","","63-68","ieeexplore.ieee.org","2017","","https://ieeexplore.ieee.org/abstract/document/8005592/;http://dx.doi.org/10.1109/MTITS.2017.8005592","10.1109/MTITS.2017.8005592","","We address the problem of using computer vision based techniques to collect high-level traffic parameters in dynamic, real-world environments. This is a challenging problem that has not been sufficiently studied. Specifically, with a focus on freight vehicles, we propose a comprehensive framework for monitoring freight traffic movements at any well-defined freight traffic generator, using a network of road-side video cameras at strategic locations. The framework employs state-of-the-art computer vision algorithms to detect and recognize license plates. Moreover, we propose a plate merging algorithm to tackle occlusion of freight vehicles. We also propose an algorithm to match the video camera datasets across different locations to derive the operational history for individual freight vehicles. We have implemented the framework and deployed it for monitoring a large retail mall over 4 days in Singapore. The proposed framework has been used to process terabytes of videos and compute freight traffic parameters, with automatic license plate recognition of 91% accuracy under dynamic, uncontrolled video capturing conditions. With a minimal amount of additional manual processing, 98% accuracy can be achieved.","Cameras,Computer vision,Data collection,Image recognition,License plate recognition,Monitoring,Support vector machines","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Jie KS,Liu M","Computer vision based real-time information acquisition for transport traffic","ICIA 2005 - Proceedings of 2005 International Conference on Information Acquisition","2005","2005","","164-169","ieeexplore.ieee.org","2005","","https://ieeexplore.ieee.org/abstract/document/1635075/;http://dx.doi.org/10.1109/icia.2005.1635075","10.1109/icia.2005.1635075","","This paper presents a low-cost computer vision system for real time traffic monitoring. The prototype built up simply consists of a PC (or a laptop) and a web-cam camera. The hardware configuration, the software structure and the basic image processing algorithms are presented. The prototype was tested in real scene under different nature lighting conditions and showed reasonable results. After an evaluation on the results obtained, the further work needed to improve the robustness of the system is given. \textcopyright 2005 IEEE.","Computer vision,Information acquisition,Motion estimation,Real-time image processing,Traffic monitoring","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Elahi MM,Yasir R,Syrus MA,Nine MS,Hossain I,Ahmed N","Computer vision based road traffic accident and anomaly detection in the context of Bangladesh","2014 International Conference on Informatics, Electronics and Vision, ICIEV 2014","2014","","","","ieeexplore.ieee.org","2014","","https://ieeexplore.ieee.org/abstract/document/6850780/;http://dx.doi.org/10.1109/ICIEV.2014.6850780","10.1109/ICIEV.2014.6850780","","Road traffic accident is one of the major causes of death in Bangladesh. In this article, we propose a method that uses road side video data to learn the traffic pattern and uses vision based techniques to track and determine various kinetic features of vehicles. Finally, the proposed method detects anomaly (possibility of accident) and accidents on the road. The proposed method shows approximately 85% accuracy level in detecting special situations. \textcopyright 2014 IEEE.","Bangladesh,Computer vision,Feature extraction,Machine learning,Neural network,Road traffic accident detection,Vehicle detection","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Satti SK,Devi KS,Dhar P,Srinivasan P","Enhancing and Classifying Traffic Signs Using Computer Vision and Deep Convolutional Neural Network","Communications in Computer and Information Science","2020","1240 CCIS","","243-253","Springer","2020","1865-0937","https://link.springer.com/chapter/10.1007/978-981-15-6315-7_20;http://dx.doi.org/10.1007/978-981-15-6315-7_20","10.1007/978-981-15-6315-7_20","","We are well aware of the importance of traffic signs and road rules in our day-to-day lives. Ignorance of traffic signs and rules may lead to various road mishaps. Technology has been trying to develop “smarter cars” that are able to automatically recognize the traffic signs and understand roadways leading to a safe drive. Within these smart cars “driver alert” system is an important feature for knowing the roadway (especially the traffic signals) to alert drivers. Recognizing the traffic signs at night is still a challenging task for researchers. This can be tried to overcome by various Deep Learning models by employing Computer Vision. In this work, the data set is trained with a Convolutional Neural Network and analyzed using the Deep Learning technique on the Keras framework. Our proposed model achieved a state-of-the-art performance of 99.66% and 96.86% accuracy on the training and testing datasets respectively..","CNN,Computer vision,Deep Learning,Real time transportation,Traffic sign","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Zaki MH,Sayed T,Wang X","Computer vision approach for the classification of bike type (motorized versus non-motorized) during busy traffic in the city of Shanghai","Journal of Advanced Transportation","2016","50","3","348-362","Wiley Online Library","2016","2042-3195","https://onlinelibrary.wiley.com/doi/abs/10.1002/atr.1327;http://dx.doi.org/10.1002/atr.1327","10.1002/atr.1327","","This article describes a novel approach for the binary classification of two-wheeler road users in a dense mixed traffic intersection. The classification is a supervised procedure to differentiate between motorized and non-motorized (human-powered) bikes. Road users were first detected and tracked using object recognition methods. Classification features were then selected from the collected trajectories. The features include maximum speed, cadence frequency in addition to acceleration-based parameters. Experiments were conducted on a video data set from Shanghai, China, where cyclists as well as motorcycles tend to share the main road facilities. A sensitivity analysis was performed to assess the quality of the selected features in improving the accuracy of the classification. A performance analysis demonstrated the robustness of the proposed classification method with a correct classification rate of up to 93%. This research contributes to the literature of automated data collection and can benefit the applications in many transportation-related fields such as shared space facility planning, simulation models for two-wheelers, and behavior analysis and road safety studies.","China,bicycles,computer vision,data collection,motorcycles,road-users classification","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Zhou S,Ng ST,Yang Y,Xu JF","Integrating computer vision and traffic modeling for near-real-time signal timing optimization of multiple intersections","Sustainable Cities and Society","2021","68","","","Elsevier","2021","2210-6707","https://www.sciencedirect.com/science/article/pii/S2210670721000676;http://dx.doi.org/10.1016/j.scs.2021.102775","10.1016/j.scs.2021.102775","","Adaptive signal timing optimizations can improve the efficiency of road networks and reduce the emissions of pollutants, but most of the current studies still rely on simplified analytical methods to depict complex road transport systems and focus on optimizing traffic signals at an isolated intersection. A framework that integrates computer vision and traffic modeling is proposed to link the real-world transport systems and operable virtual traffic models for the signal timing optimization at multiple intersections. The integrative framework consists of six main steps, including configuring real-time video sources, conducting transfer-learning to develop the vehicle detector, comparing and selecting vehicle trackers, collecting traffic parameters by referring to the CV-TM ontology, establishing and running the traffic model, and operating simulation-based optimizations. The proposed integrative framework is demonstrated through a case study of the signal timing optimization at multi-intersections in a real-world road network. Three critical information items including the traffic volumes, vehicle compositions, and vehicles' turning ratios are derived from real-time surveillance videos, and the extracted information is then automatically incorporated into TM to optimize the signal timings of interconnected intersections in a near-real-time manner. In comparison with the original signal scheme, the optimized one can reduce 14.2 % of average vehicle delays, 18.9 % of vehicle stops, 9.1 % of average travel time, and 2.3 % of pollutant emissions in this specific case. The results indicate that synchronously optimizing signal timings at multiple intersections increase not only the transportation efficiency but also the environmental friendliness of road transport systems. The proposed CV-TM integration framework is demonstrated to be a promising way for conducting near-real-time signal timing optimizations in intricate traffic scenes instead of at isolated intersections, helping decision-makers to promptly respond to the time-varying traffic conditions during various real-world events, and facilitating the transportation systems and cities to achieve sustainable development goals.","Computer vision,Ontology,Signal timing,Traffic modeling,Transfer learning","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Salimullina AD,Budanov DO","Computer Vision System for Speed Limit Traffic Sign Recognition","Proceedings of the 2022 Conference of Russian Young Researchers in Electrical and Electronic Engineering, ElConRus 2022","2022","","","415-418","ieeexplore.ieee.org","2022","","https://ieeexplore.ieee.org/abstract/document/9755744/;http://dx.doi.org/10.1109/ElConRus54750.2022.9755744","10.1109/ElConRus54750.2022.9755744","","The paper is devoted to the development of a portable speed limit traffic sign recognition system widely available for general use. A shape-based approach has been applied to detect a speed limit sign. The sign recognition has been carried out with a convolutional neural network. A single board computer was used as a prototype of a hardware part of the proposed system. The hardware and software parts of the proposed system have been developed and tested. The traffic sign detection range is 25 meters in case of good lighting, the average recognition time is 5 seconds. The methods and techniques to increase system performance have been proposed.","computer vision,image recognition,machine learning,neural network,single-board computer,traffic sign recognition","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Ubaid MT,Saba T,Draz HU,Rehman A,Ghani MU,Kolivand H","Intelligent Traffic Signal Automation Based on Computer Vision Techniques Using Deep Learning","IT Professional","2022","24","1","27-33","ieeexplore.ieee.org","2022","1941-045X","https://ieeexplore.ieee.org/abstract/document/9717356/;http://dx.doi.org/10.1109/MITP.2021.3121804","10.1109/MITP.2021.3121804","","Traffic congestion in highly populated urban areas is a huge problem these days. A lot of researchers have proposed many systems to monitor traffic flow and handle congestion through different techniques. But the current systems are not reliable enough to perceive traffic signals in real-time. Therefore, we aim to build a system that can efficiently perform real-time environments to solve the traffic congestion problem through signal automation. Since vehicle detection and counting are crucial in any traffic system, we use state-of-the-art deep learning techniques to detect and count vehicles in real-time. We then automate the signal timings by comparing the count of traffic on all sides of a junction. These automated signal timings sufficiently reduce congestion and improve traffic flow. We prepared a dataset of 4500 images and achieved about 91% accuracy by training it on Faster RCNN.","Artificial intelligence,Deep learning,Intelligent transportation systems,Monitoring,Real-time systems,Traffic congestion,Traffic control,Urban areas,Vehicle detection","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Umair M,Farooq MU,Raza RH,Chen Q,Abdulhai B","Efficient video-based vehicle queue length estimation using computer vision and deep learning for an urban traffic scenario","Processes","2021","9","10","","mdpi.com","2021","2227-9717","https://www.mdpi.com/1303826;http://dx.doi.org/10.3390/pr9101786","10.3390/pr9101786","","In the traffic engineering realm, queue length estimation is considered one of the most critical challenges in the Intelligent Transportation System (ITS). Queue lengths are important for determining traffic capacity and quality, such that the risk for blockage in any traffic lane could be minimized. The Vision-based sensors show huge potentials compared to fixed or moving sensors as they offer flexibility for data acquisition due to large-scale deployment at a huge pace. Compared to others, these sensors offer low installation/maintenance costs and also help with other traffic surveillance related tasks. In this research, a CNN-based approach for estimation of vehicle queue length in an urban traffic scenario using low-resolution traffic videos is proposed. The system calculates queue length without the knowledge of any camera parameter or onsite calibration information. The estimation in terms of the number of cars is considered a priority as compared to queue length in the number of meters since the vehicular delay is the number of waiting cars times the wait time. Therefore, this research estimates queue length based on total vehicle count. However, length in meters is also provided by approximating average vehicle size as 5 m. The CNNbased approach helps with accurate tracking of vehicles' positions and computing queue lengths without the need for installation of any roadside or in-vehicle sensors. Using a pre-trained 80-classes YOLOv4 model, an overall accuracy of 73% and 88% was achieved for vehicle-based and pixel-based queue length estimation. After further fine-tuning of model on the low-resolution traffic images and narrowing down the output classes to vehicle class only, an average accuracy of 83% and 93%, respectively, was achieved which shows the efficiency and robustness of the proposed approach.","Artificial intelligence,Computer vision,Convolutional neural networks,Deep learning,Intelligent transportation system,Vehicle queue length,YOLO","Query date: 2023-03-13 22:02:47","",""
"Journal Article","Houben S,Stallkamp J,Salmen J,Schlipsing M,Igel C","Detection of traffic signs in real-world images: The German traffic sign detection benchmark","Proceedings of the International Joint Conference on Neural Networks","2013","","","","ieeexplore.ieee.org","2013","","https://ieeexplore.ieee.org/abstract/document/6706807/;http://dx.doi.org/10.1109/IJCNN.2013.6706807","10.1109/IJCNN.2013.6706807","","Real-time detection of traffic signs, the task of pinpointing a traffic sign's location in natural images, is a challenging computer vision task of high industrial relevance. Various algorithms have been proposed, and advanced driver assistance systems supporting detection and recognition of traffic signs have reached the market. Despite the many competing approaches, there is no clear consensus on what the state-of-the-art in this field is. This can be accounted to the lack of comprehensive, unbiased comparisons of those methods. We aim at closing this gap by the 'German Traffic Sign Detection Benchmark' presented as a competition at IJCNN 2013 (International Joint Conference on Neural Networks). We introduce a real-world benchmark data set for traffic sign detection together with carefully chosen evaluation metrics, baseline results, and a web-interface for comparing approaches. In our evaluation, we separate sign detection from classification, but still measure the performance on relevant categories of signs to allow for benchmarking specialized solutions. The considered baseline algorithms represent some of the most popular detection approaches such as the Viola-Jones detector based on Haar features and a linear classifier relying on HOG descriptors. Further, a recently proposed problem-specific algorithm exploiting shape and color in a model-based Houghlike voting scheme is evaluated. Finally, we present the best-performing algorithms of the IJCNN competition. \textcopyright 2013 IEEE.","Benchmark testing,Detectors,Feature extraction,Image color analysis,Image edge detection,Shape,Training","Query date: 2023-03-14 03:28:52","",""
"Journal Article","Shustanov A,Yakimov P","CNN Design for Real-Time Traffic Sign Recognition","Procedia Engineering","2017","201","","718-725","Elsevier","2017","1877-7058","https://www.sciencedirect.com/science/article/pii/S1877705817341231;http://dx.doi.org/10.1016/j.proeng.2017.09.594","10.1016/j.proeng.2017.09.594","","Nowadays, more and more object recognition tasks are being solved with Convolutional Neural Networks (CNN). Due to its high recognition rate and fast execution, the convolutional neural networks have enhanced most of computer vision tasks, both existing and new ones. In this article, we propose an implementation of traffic signs recognition algorithm using a convolution neural network. The paper also shows several CNN architectures, which are compared to each other. Training of the neural network is implemented using the TensorFlow library and massively parallel architecture for multithreaded programming CUDA. The entire procedure for traffic sign detection and recognition is executed in real time on a mobile GPU. The experimental results confirmed high efficiency of the developed computer vision system.","Computer Vision,Convolutional Neural Networks,Image Processing,Mobile GPU,TensorFlow,Traffic Sign Recognition","Query date: 2023-03-14 03:28:52","",""
"Journal Article","Varagula J,Kulproma PA,Itob T","Object Detection Method in Traffic by On-Board Computer Vision with Time Delay Neural Network","Procedia Computer Science","2017","112","","127-136","Elsevier","2017","1877-0509","https://www.sciencedirect.com/science/article/pii/S1877050917315429;http://dx.doi.org/10.1016/j.procs.2017.08.185","10.1016/j.procs.2017.08.185","","A collision avoidance system play an important role in reducing incidents occurring on the road, which the object detection is crucial to enable obstacle avoidance for this system. The objective of this paper is to improve general object detection methods for vehicles in order to prevent a collision of the vehicles and the obstacles - of which we do not know the exact shape, size or color. A combined computer vision system with artificial neural networks can improve the performance of the vehicle has the ability to see and recognize the obstacles like human beings. In this paper, the authors present the algorithm for vehicles to detect general objects, which can classify obstacles that are real obstacles or fake obstacles, such as a painting or text on the road. The proposed method, we combined on-board computer vision system based on Histograms of Oriented Gradient (HOG) and Time Delay Neural Network (TDNN). We extract feature of the obstacles by HOG and using TDNN to recognize and classify the obstacles. The experimental results showed that this system can detect general objects, and is not restricted to vehicles, objects or pedestrians. It has provided good results along with high accuracy and reliability, which it is accurate enough to provide a warning to the driver when a collision is imminent.","HOG,computer vision,object classification,time delay neural network","Query date: 2023-03-14 03:28:52","",""
"Journal Article","González Á,Bergasa LM,Gavilán M,Sotelo MA,Herranz F,Fernández C","Automatic information extraction of traffic panels based on computer vision","IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC","2009","","","184-189","ieeexplore.ieee.org","2009","","https://ieeexplore.ieee.org/abstract/document/5309872/;http://dx.doi.org/10.1109/ITSC.2009.5309872","10.1109/ITSC.2009.5309872","","Computer vision systems used on road maintenance, either related to signs or to the road itself, are playing a major role in many countries because of the higher investment on public works of this kind. These systems are able to collect a wide range of information automatically and quickly, with the aim of improving road safety. In this context, the suitability of the information contained on the road signs located above the road, typically known as traffic panels, is vital for a correct and safe use by the road user. This paper describes an approach to the first steps of a developing system which will be able to make an inventory and to check the reliability of the information contained on the traffic panels, and whose final aim is to take part on an automatic visual inspection system of signs and panels. \textcopyright 2009 IEEE.","Hough transform,Image segmentation,Panel reorientation,Traffic panels","Query date: 2023-03-14 03:28:52","",""
"Journal Article","Zhu H,Xu C,Li F","The traffic volume count algorithm based on computer vision","Proceedings - 2013 5th International Conference on Intelligent Human-Machine Systems and Cybernetics, IHMSC 2013","2013","1","","130-133","ieeexplore.ieee.org","2013","","https://ieeexplore.ieee.org/abstract/document/6643850/;http://dx.doi.org/10.1109/IHMSC.2013.38","10.1109/IHMSC.2013.38","","This paper proposes a vehicle detection and traffic volume statistics algorithm Based on an improved single Gaussian model. This algorithm contains three major sections, which are moving target detection, shadows suppression and traffic volume count. Firstly, with an improved background initialization method, the paper detects the moving target by using the single Gaussian model. Then, a computational method of Shadows suppression is presented in the RGB feature space. Finally, the traffic volume is counted in the virtual areas of lanes. Two experiments are performed on the algorithm. The results show that the algorithm can detect vehicle quickly and have a higher recognition rate. It can works well in the actual conditions. \textcopyright 2013 IEEE.","Computer vision,Gaussian model,Shadows suppression,Traffic volume","Query date: 2023-03-14 03:28:52","",""
"Journal Article","Gupta S,Sundar B","A Computer Vision Based Approach for Automated Traffic Management as a Smart City Solution","Proceedings of CONECCT 2020 - 6th IEEE International Conference on Electronics, Computing and Communication Technologies","2020","","","","ieeexplore.ieee.org","2020","","https://ieeexplore.ieee.org/abstract/document/9198588/;http://dx.doi.org/10.1109/CONECCT50063.2020.9198588","10.1109/CONECCT50063.2020.9198588","","This study aims to provide a solution to the incessant land acquisition to surmount growing traffic by promoting the application of adaptable lane dividers meant to be implemented in smart cities. A flexible lane span manipulates the width of the road as a whole, avoiding the need for road expansion. Video data is obtained from cameras placed along a single stretch and is analyzed in real-time. The model uses Computer Vision, ROI (Region of Interest) based execution, exploiting both traffic speed and occupied lane area to determine traffic density. Each camera is assigned a priority value with cameras down the lane possessing higher priority. The decision of each camera constitutes the final decision. The design also adopts pattern recognition based on learning, besides real-time analysis for more conclusive results.","Aggregation,Computer Vision,Data Cube,Lane detection,Real-time video,Spatial Temporal Identification,Traffic management","Query date: 2023-03-14 03:28:52","",""
"Journal Article","Gokasar I,Timurogullari A","Real-time prediction of traffic density with deep learning using computer vision and traffic event information","2021 International Conference on INnovations in Intelligent SysTems and Applications, INISTA 2021 - Proceedings","2021","","","","ieeexplore.ieee.org","2021","","https://ieeexplore.ieee.org/abstract/document/9548434/;http://dx.doi.org/10.1109/INISTA52262.2021.9548434","10.1109/INISTA52262.2021.9548434","","Traffic congestion affects urban areas negatively in many ways. Therefore, successful and efficient traffic management is a necessity to solve or at least alleviate traffic congestion. Hence, the usage of high-quality data is not only essential but also mandatory. Prediction of traffic behaviour over a certain period of time should be done using various characteristics and related data of traffic. In this study, the location, lane, and time data of each vehicle are obtained from cameras located in D100 Highway by computer vision. Besides, the event matrices are created manually to detect the circumstances such as shoulder violation, police stop, police control, traffic flow control, weather, vehicle on the shoulder, and police or ambulance on the shoulder. The effect of the different dynamics of these events in different lanes has been transformed into a single ""Event Score""with the help of the weight coefficients obtained from Logistic Regression. Afterward, the traffic density and traffic event datasets are combined to predict the next frame of the traffic. Among the many prediction algorithms tested in this study, Support Vector Machine (SVM) and Recurrent Neural Networks (RNN) were able to predict the traffic density after 1, 3, and 5 minutes with the highest accuracy. As a result of this study, it has been observed that estimation algorithms using ""Event Score""obtained with separate coefficients for each lane and historical traffic density data as independent variables give successful results in dynamic and/or static traffic density estimation.","Computer vision,Deep learning,Machine learning","Query date: 2023-03-14 03:28:52","",""
"Journal Article","Li X,Wang K,Tian Y,Yan L,Deng F,Wang FY","The ParallelEye dataset: A large collection of virtual images for traffic vision research","IEEE Transactions on Intelligent Transportation Systems","2019","20","6","2072-2084","ieeexplore.ieee.org","2019","1524-9050","https://ieeexplore.ieee.org/abstract/document/8451919/;http://dx.doi.org/10.1109/TITS.2018.2857566","10.1109/TITS.2018.2857566","","Dataset plays an essential role in the training and testing of traffic vision algorithms. However, the collection and annotation of images from the real world is time-consuming, labor-intensive, and error-prone. Therefore, more and more researchers have begun to explore the virtual dataset, to overcome the disadvantages of real datasets. In this paper, we propose a systematic method to construct large-scale artificial scenes and collect a new virtual dataset (named 'ParallelEye') for the traffic vision research. The Unity3D rendering software is used to simulate environmental changes in the artificial scenes and generate ground-truth labels automatically, including semantic/instance segmentation, object bounding boxes, and so on. In addition, we utilize ParallelEye in combination with real datasets to conduct experiments. The experimental results show the inclusion of virtual data helps to enhance the per-class accuracy in object detection and semantic segmentation. Meanwhile, it is also illustrated that the virtual data with controllable imaging conditions can be used to design evaluation experiments flexibly.","ParallelEye,Traffic vision,artificial scenes,complex environments,parallel vision,virtual dataset","Query date: 2023-03-14 03:28:52","",""
"Journal Article","Bouaafia S,Messaoud S,Maraoui A,Ammari AC,Khriji L,MacHhout M","Deep Pre-Trained Models for Computer Vision Applications: Traffic sign recognition","18th IEEE International Multi-Conference on Systems, Signals and Devices, SSD 2021","2021","","","23-28","ieeexplore.ieee.org","2021","","https://ieeexplore.ieee.org/abstract/document/9429420/;http://dx.doi.org/10.1109/SSD52085.2021.9429420","10.1109/SSD52085.2021.9429420","","Objects detection and Recognition are an important task for computer vision field and intelligent transportation systems. Generally, these tasks remain challenging for the artificial machines due to the need of pre-learning phase in which the machine acquires an intelligent brain. Some researchers have shown that deep learning tools work well in computer vision, image processing, and pattern recognition. To solve such tasks, this paper focuses on deep Convolutional Neural Network (CNN) and its architectures, such as, VGG16, VGG19, AlexNet, and Resnet50. An overview for the techniques and schemes used for computer vision applications such as Road Sign Recognition will be introduced. Then by customizing the hyperparameters for each pre-Trained models, we re-implement these models for the traffic sign recognition application. In the experiments, these pre-Trained CNN classifiers are trained and tested with the German Traffic Sign Recognition Benchmark dataset (GTSRB). Experimental results show that the proposed scheme achieved a good performance results in terms of evaluations metrics of traffic signs recognition. A performance comparison analysis between the selected pre-Trained models for traffic sign recognition confirmed that the AlexNet model outperforms all other implemented models.","Deep Convolutional Neural Network,Deep learning,Pre-Trained models,Traffic sign recognition","Query date: 2023-03-14 03:28:52","",""
"Journal Article","Bortnikov M,Khan A,Khattak AM,Ahmad M","Accident Recognition via 3D CNNs for Automated Traffic Monitoring in Smart Cities","Advances in Intelligent Systems and Computing","2020","944","","256-264","Springer","2020","2194-5365","https://link.springer.com/chapter/10.1007/978-3-030-17798-0_22;http://dx.doi.org/10.1007/978-3-030-17798-0_22","10.1007/978-3-030-17798-0_22","","Automatic recognition of road accidents in traffic videos can improve road safety. Smart cities can deploy accident recognition systems to promote urban traffic safety and efficiency. This work reviews existing approaches for automatic accident detection and highlights a number of challenges that make accident detection a difficult task. Furthermore, we propose to implement a 3D Convolutional Neural Network (CNN) based accident detection system. We customize a video game to generate road traffic video data in a variety of weather and lighting conditions. The generated data is preprocessed using optical flow method and injected with noise to focus only on motion and introduce further variations in the data, respectively. The resulting data is used to train the model, which was then tested on real-life traffic videos from YouTube. The experiments demonstrate that the performance of the proposed algorithm is comparable to that of the existing models, but unlike them, it is not dependent on a large volume of real-life video data for training and does not require manual tuning of any thresholds.","3D convolutional neural networks,Accident recognition,Computer vision,Deep learning,Machine learning","Query date: 2023-03-14 03:28:52","",""
"Journal Article","Chen X,Chen Y,Zhang G","A computer vision algorithm for locating and recognizing traffic signal control light status and countdown time","Journal of Intelligent Transportation Systems: Technology, Planning, and Operations","2021","25","5","533-546","Taylor &Francis","2021","1547-2442","https://www.tandfonline.com/doi/abs/10.1080/15472450.2021.1871611;http://dx.doi.org/10.1080/15472450.2021.1871611","10.1080/15472450.2021.1871611","","It is of practical importance for individual vehicles to automatically identify traffic signal light status to facilitate their decision makings for traffic safety performance enhancement and operation efficiency maximization when they are approaching intersections, especially in near-future fully-or semi-autonomous vehicle-penetrated traffic systems. Traditional methods aim to directly extract information from the light emitting area of a traffic signal light head, but this can easily result in missed or false signal light status identification due to changes in detection distance and lighting conditions. To address these research gaps, an innovative computer vision-based algorithm is developed for signal control light status identification and countdown time recognition. Based on the unique characteristics of black traffic light boards, color segmentation is conducted in both RGB and HSV channels, and traffic light boards and countdown time display boards are located through cascade filtering algorithms. In the HSV color space, the H component can be extracted and highlighted to determine the current signal status by distinguishing the distribution of the pixel points of the H component. Based on the nearest neighbor interpolation algorithm, an adaptive threading method is developed to improve countdown time recognition. The experimental tests were conducted to verify the effectiveness of the developed approach under various scenarios with acceptable recognition accuracy and execution efficiency. The developed approach can be applied and integrated with other detection and control algorithms to strengthen vehicle-crossing safety performance and operational efficiency at intersections.","Cascade filtering,color recognition,digital countdown time recognition,multi-color space fusion","Query date: 2023-03-14 03:28:52","",""
"Journal Article","Dhage MR,Patil GV,Mistry SJ,Tambe PN,Nankar PH","Automatic traffic E-challan generation using computer vision","Lecture Notes on Data Engineering and Communications Technologies","2020","39","","203-213","Springer","2020","2367-4520","https://link.springer.com/chapter/10.1007/978-3-030-34515-0_21;http://dx.doi.org/10.1007/978-3-030-34515-0_21","10.1007/978-3-030-34515-0_21","","The Automatic recognition of license plate is the basis of effective management in traffic, the automatic detection and localization of license plate is an important part. License plate detection and contain how to extract or segment the license plate region from the license plate image a new deep learning network structure was designed, and designed network structure was used to detect and locate the license plate automatically. The system proposed by us involves automatic detection of vehicles that break the traffic rules at respective signals and registration number for every vehicle is recognized. The vehicle number detected is searched in the database for type of vehicle and owner's information. This information is used to generate e-challan in the name of the person who owes the vehicle directly and instantly and send appropriate fine message to the owner. So it will be more efficient and will require less human intervention.","Contour,E-challan,Otsu,Tesseract","Query date: 2023-03-14 03:28:52","",""
